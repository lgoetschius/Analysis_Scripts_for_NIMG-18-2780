{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>619 Analysis</center></h1>\n",
    "\n",
    "The analyses below are the final (or final until I get feedback from the PIs) analysis for my 619 data. I have modeled this analysis after Greening & Mitchell, 2015 in Human Brain Mapping. In this analysis, we are using a machine learning permutation test of a Ridge Regression model with the probability of connectivity of the amygdala with eight Brodmann's Areas located in the prefrontal cortex. After that, we used 1000 iterations of a training and test dataset where a unique 80% of the data is allocted to the training dataset and a unique 20% to the test dataset to determine which coefficients were reliably contributing to the model. Here's what that looks likes for the left and right hemispheres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is necessary for the plots to print in the jupyter notebook here.\n",
    "%matplotlib inline\n",
    "# Import the necessary packages (double check to make sure that all of these are used).\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import permutation_test_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the data. \n",
    "#filename = '/Users/leighgayle/Box Sync/Final_619_Docs/ProbtrackData_NoScalpSubList_wDti_Final_120117.csv'\n",
    "filename = '/Users/leighgayle/Box Sync/Final_619_Docs/ProbtrackData_NoScalpSubList_wDti_Final_103018.csv'\n",
    "#filename = '/Users/leighgayle/Box Sync/ThreatDep_Probtrack_Amygdala/Amy_NewProbtrack_nomissing.csv'\n",
    "data = pd.read_csv(filename, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to remove the outliers in the data now that are calculated in R because it seems like a giant pain to figure out how to do it in python when I already know how to calculate influential outliers in R. Fun fact for everyone in the room--R is 1 index and python is 0 index. The outiers detected in R were 12, 75, 82, 89, 99, and 146. That would make them 11, 74, 81, 88, 98, and 145 in python. I'm taking them out in reverse so It doesn't mess with the earlier indexing.\n",
    "\n",
    "The subjects removed are 10023, 10116, 10125, 10136, 10155, and 10234.\n",
    "\n",
    "These outliers are removed based on Cook's Distance of the linear regression models with the cutoff being 4/(n-k-1) or 0.029."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove outliers detected in our R dataset.  \n",
    "#clean_data = data.drop(145)\n",
    "clean_data = data.drop(144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_data = clean_data.drop(98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_data = clean_data.drop(88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_data = clean_data.drop(81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_data = clean_data.drop(74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_data = clean_data.drop(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check to make sure the subjects that we want to be deleted are deleted--success.\n",
    "clean_data.to_csv(path_or_buf='clean_data_output_final_052818.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scale the data -- this should be done in Ridge Regression\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(clean_data[[\"Threat_Act_Ramy_NoScalp\",\"RAmySeed_BA25Target\",\"RAmySeed_BA24Target\",\"RAmySeed_BA32Target\",\"RAmySeed_BA10Target\", \"RAmySeed_BA9Target\", \"RAmySeed_BA46Target\",\"RAmySeed_BA11Target\",\"RAmySeed_BA47Target\",\"Threat_Act_Lamy_NoScalp\",\"LAmySeed_BA25Target\",\"LAmySeed_BA24Target\",\"LAmySeed_BA32Target\",\"LAmySeed_BA10Target\", \"LAmySeed_BA9Target\", \"LAmySeed_BA46Target\",\"LAmySeed_BA11Target\",\"LAmySeed_BA47Target\"]])\n",
    "#StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "#scaled_data = scaler.transform(clean_data[[\"Threat_Act_Ramy_NoScalp\",\"RAmySeed_BA25Target\",\"RAmySeed_BA24Target\",\"RAmySeed_BA32Target\",\"RAmySeed_BA10Target\", \"RAmySeed_BA9Target\", \"RAmySeed_BA46Target\",\"RAmySeed_BA11Target\",\"RAmySeed_BA47Target\",\"Threat_Act_Lamy_NoScalp\",\"LAmySeed_BA25Target\",\"LAmySeed_BA24Target\",\"LAmySeed_BA32Target\",\"LAmySeed_BA10Target\", \"LAmySeed_BA9Target\", \"LAmySeed_BA46Target\",\"LAmySeed_BA11Target\",\"LAmySeed_BA47Target\"]])\n",
    "\n",
    "# Actually, normalize option will take care of this. I will keep this in here in case I would like to switch it back eventually, but I think how we have the data currently is sufficient. \n",
    "# Similarly, I'll keep the scaled data options commented out below, I do not use them at the current moment though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify the X and y as scaled variables\n",
    "y_r = clean_data.Threat_Act_Ramy_NoScalp\n",
    "X_r = clean_data[[\"RAmySeed_BA25Target\",\"RAmySeed_BA24Target\",\"RAmySeed_BA32Target\",\"RAmySeed_BA10Target\", \"RAmySeed_BA9Target\",\"RAmySeed_BA11Target\",\"RAmySeed_BA47Target\"]]\n",
    "#y_r = scaled_data[:,0]\n",
    "#X_r = scaled_data[:,[1,2,3,4,5,7,8]]\n",
    "\n",
    "y_l = clean_data.Threat_Act_Lamy_NoScalp\n",
    "X_l = clean_data[[\"LAmySeed_BA25Target\",\"LAmySeed_BA24Target\",\"LAmySeed_BA32Target\",\"LAmySeed_BA10Target\", \"LAmySeed_BA9Target\",\"LAmySeed_BA11Target\",\"LAmySeed_BA47Target\"]]\n",
    "#y_l = scaled_data[:,9]\n",
    "#X_l = scaled_data[:,[10,11,12,13,14,16,17]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the variables loaded in, it's time to have the RidgeCV command choose which regularization parameter fits the data. We'll look at it for both of our regression equations, but it ends up being the same. \n",
    "\n",
    "The command below is creating a ridge model where it's cycling through alphas between 1 and 10 with steps of 0.01. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pick which alpha to use. \n",
    "ridgeCV = linear_model.RidgeCV(alphas=[0.1, 0.001, 10.0], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right\n",
    "ridgeCV.fit(X_r,y_r)\n",
    "print \"The suggested regularization parameter for the right hemisphere regression is {}\".format(ridgeCV.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left\n",
    "ridgeCV.fit(X_l,y_l)\n",
    "print \"The suggested regularization parameter for the left hemisphere regression is {}\".format(ridgeCV.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define our ridge regression model.\n",
    "ridge = linear_model.Ridge(alpha=0.1, normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Right Hemisphere Model Test</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#score_R, permuatation_scores_R, pvalue_R = permutation_test_score(ridge, X_r, y_r, cv=6, scoring = 'neg_mean_squared_error', n_permutations=5000, n_jobs=1)\n",
    "score_R, permuatation_scores_R, pvalue_R = permutation_test_score(ridge, X_r, y_r, cv=6, scoring = 'neg_mean_squared_error', n_permutations=5000, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('clean_r_hemisphere_permutation_scores_final_103018.csv', 'w') as csvfile:\n",
    "    listwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    listwriter.writerow(permuatation_scores_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the permutations.\n",
    "#tnr_font = {'fontname':'Times New Roman'}\n",
    "\n",
    "from mpl_toolkits.axes_grid.axislines import Subplot\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "fig = plt.figure()\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "ax = Subplot(fig, 111)\n",
    "fig.add_subplot(ax)\n",
    "\n",
    "ax.axis[\"right\"].set_visible(False)\n",
    "ax.axis[\"top\"].set_visible(False)\n",
    "\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 16\n",
    "\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "n_classes = np.unique(y_r).size\n",
    "plt.hist(permuatation_scores_R*-1, 20, label='Permutation MSE Scores',\n",
    "         edgecolor='black',color='grey')\n",
    "ylim = plt.ylim()\n",
    "plt.plot(2 * [score_R*-1], ylim, '--g', linewidth=3,\n",
    "         label='Predicted MSE Score'\n",
    "         ' (p-value %.3f)' % pvalue_R, color='k')\n",
    "\n",
    "plt.ylim(ylim)\n",
    "plt.legend()\n",
    "plt.xlabel('Score', fontsize='large')\n",
    "plt.ylabel('Number of Permutations', fontsize='large')\n",
    "\n",
    "#plt.title(r\"${\"+ str('Figure' '\\ XX:')+\"}$\" + 'Threat Amygdala Activation (Right) Predicted by Prefrontal Probabilistic Tractography', y=-.3, fontsize='medium')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's look at the individual coefficients now.\n",
    "# configure bootstrap\n",
    "#clean_vals = clean_data.values\n",
    "clean_vals = clean_data.values\n",
    "n_iterations = 1000\n",
    "n_size = int(len(clean_vals) * 0.84)\n",
    "# run bootstrap\n",
    "#with open('r_hemisphere_coefficients_newprobtrack_072318.csv', 'w') as csvfile:\n",
    "#    listwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "#    for i in range(n_iterations):\n",
    "#        # prepare train and test sets\n",
    "#        train = resample(clean_vals, n_samples=n_size)\n",
    "#        test = np.array([x for x in clean_vals if x.tolist() not in train.tolist()])\n",
    "#        # fit model\n",
    "#        ridge.fit(train[:,[23,25,27,29,31,35,37,4]], train[:,15])\n",
    "#        # evaluate model\n",
    "#        predictions = ridge.predict(test[:,[23,25,27,29,31,35,37,4]])\n",
    "#        listwriter.writerow(ridge.coef_)\n",
    "        \n",
    "\n",
    "# run bootstrap\n",
    "with open('clean_r_hemisphere_coefficients_final_110818.csv', 'w') as csvfile:\n",
    "    listwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in range(n_iterations):\n",
    "        # prepare train and test sets\n",
    "        train = resample(clean_vals, n_samples=n_size)\n",
    "        test = np.array([x for x in clean_vals if x.tolist() not in train.tolist()])\n",
    "        # fit model\n",
    "        ridge.fit(train[:,[23,25,27,29,31,35,37]], train[:,15])\n",
    "        # evaluate model\n",
    "        predictions = ridge.predict(test[:,[23,25,27,29,31,35,37]])\n",
    "        listwriter.writerow(ridge.coef_)\n",
    "    \n",
    "    \n",
    "#    with open('r_hemisphere_coefficients_110818.csv', 'w') as csvfile:\n",
    "#    listwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "#    for i in range(n_iterations):\n",
    "#        # prepare train and test sets\n",
    "#        train = resample(clean_vals, n_samples=n_size)\n",
    "#        test = np.array([x for x in clean_vals if x.tolist() not in train.tolist()])\n",
    "#        # fit model\n",
    "#        ridge.fit(train[:,[16,17,18,19,20,21,22]], train[:,8])\n",
    "#        # evaluate model\n",
    "#        predictions = ridge.predict(test[:,[16,17,18,19,20,21,22]])\n",
    "#        listwriter.writerow(ridge.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.fit(X_r,y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('predicted_r_vals_final_103018.csv', 'w') as csvfile:\n",
    "    listwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    listwriter.writerow(ridge.predict(X_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Left Hemisphere Model Test</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_L, permuatation_scores_L, pvalue_L = permutation_test_score(ridge, X_l, y_l, cv=6, scoring = 'neg_mean_squared_error', n_permutations=5000, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('clean_l_hemisphere_permutation_scores_final_050718.csv', 'w') as csvfile:\n",
    "    listwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    listwriter.writerow(permuatation_scores_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the permutations.\n",
    "fig = plt.figure()\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "ax = Subplot(fig, 111)\n",
    "fig.add_subplot(ax)\n",
    "\n",
    "ax.axis[\"right\"].set_visible(False)\n",
    "ax.axis[\"top\"].set_visible(False)\n",
    "\n",
    "plt.hist(permuatation_scores_L*-1, 20, label='Permutation MSE Scores',\n",
    "         edgecolor='black', color='grey')\n",
    "ylim = plt.ylim()\n",
    "plt.plot(2 * [score_L*-1], ylim, '--g', linewidth=3,\n",
    "         label='Predicted MSE Score'\n",
    "         ' (p-value %.3f)' % pvalue_L, color='k')\n",
    "\n",
    "plt.ylim(ylim)\n",
    "plt.legend()\n",
    "plt.xlabel('Score', fontsize='large')\n",
    "plt.ylabel('Number of Permutations', fontsize='large')\n",
    "plt.title(r\"${\"+ str('Figure' '\\ XX:')+\"}$\" + 'Threat Amygdala Activation (Left) Predicted by Prefrontal Probabilistic Tractography', y=-.3, fontsize=MEDIUM_SIZE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run bootstrap\n",
    "clean_vals = clean_data.values\n",
    "n_iterations = 1000\n",
    "n_size = int(len(clean_vals) * 0.84)\n",
    "with open('clean_l_hemisphere_coefficients_final_110818.csv', 'w') as csvfile:\n",
    "    listwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in range(n_iterations):\n",
    "        # prepare train and test sets\n",
    "        train = resample(clean_vals, n_samples=n_size)\n",
    "        test = np.array([x for x in clean_vals if x.tolist() not in train.tolist()])\n",
    "        # fit model\n",
    "        ridge.fit(train[:,[22,24,26,28,30,34,36]], train[:,16])\n",
    "        # evaluate model\n",
    "        predictions = ridge.predict(test[:,[22,24,26,28,30,34,36]])\n",
    "        listwriter.writerow(ridge.coef_)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge.fit(X_l,y_l)\n",
    "with open('predicted_l_vals_final_103018.csv', 'w') as csvfile:\n",
    "    listwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    listwriter.writerow(ridge.predict(X_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted test scores were saved out as csv files. I then rank ordered the values and all of the predicted values and the coefficients that were reliably less than 0, meaning that more than 950 had coefficients less than 0, I consider to contribute reliably. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick look added 5.24.2018 to look at all Faces models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_LAF, permuatation_scores_LAF, pvalue_LAF = permutation_test_score(ridge, X_l, y_l_af, cv=6, scoring = 'neg_mean_squared_error', n_permutations=5000, n_jobs=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_LAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_LAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_RAF, permuatation_scores_RAF, pvalue_RAF = permutation_test_score(ridge, X_r, y_r_af, cv=6, scoring = 'neg_mean_squared_error', n_permutations=5000, n_jobs=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_RAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_RAF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyses done post R&R\n",
    "## Analyses done 1.7.2019 - 1.11.2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/leighgayle/Box Sync/Final_619_Docs/NeuroImage_Submission/R&R/clean_updated_datafile.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(filename, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_r = data.Threat_Act_Ramy_NoScalp\n",
    "y_r_happy = data.happyGTbaseline_right\n",
    "y_r_sad = data.sadGTbaseline_right\n",
    "X_r = data[[\"RAmySeed_BA25Target\",\"RAmySeed_BA24Target\",\"RAmySeed_BA32Target\",\"RAmySeed_BA10Target\", \"RAmySeed_BA9Target\",\"RAmySeed_BA11Target\",\"RAmySeed_BA47Target\",\"puberty_score\",\"Gender\",\"Internalizing\"]]\n",
    "\n",
    "y_l = data.Threat_Act_Lamy_NoScalp\n",
    "y_l_happy = data.happyGTbaseline_left\n",
    "y_l_sad = data.sadGTbaseline_left\n",
    "X_l = data[[\"LAmySeed_BA25Target\",\"LAmySeed_BA24Target\",\"LAmySeed_BA32Target\",\"LAmySeed_BA10Target\", \"LAmySeed_BA9Target\",\"LAmySeed_BA11Target\",\"LAmySeed_BA47Target\",\"puberty_score\",\"Gender\",\"Internalizing\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our ridge regression model.\n",
    "ridge = linear_model.Ridge(alpha=0.1, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_R, permuatation_scores_R, pvalue_R = permutation_test_score(ridge, X_r, y_r, cv=6, scoring = 'neg_mean_squared_error', n_permutations=5000, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_L, permuatation_scores_L, pvalue_L = permutation_test_score(ridge, X_l, y_l, cv=6, scoring = 'neg_mean_squared_error', n_permutations=5000, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = data.values\n",
    "n_iterations = 1000\n",
    "n_size = int(len(vals) * 0.84)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run bootstrap\n",
    "with open('clean_r_hemisphere_coefficients_wcovariates_010819.csv', 'w') as csvfile:\n",
    "    listwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in range(n_iterations):\n",
    "        # prepare train and test sets\n",
    "        train = resample(vals, n_samples=n_size)\n",
    "        test = np.array([x for x in vals if x.tolist() not in train.tolist()])\n",
    "        # fit model\n",
    "        ridge.fit(train[:,[24, 26, 28, 30, 32, 36, 38, 2, 44, 45]], train[:,16])\n",
    "        # evaluate model\n",
    "        predictions = ridge.predict(test[:,[24, 26, 28, 30, 32, 36, 38, 2, 44, 45]])\n",
    "        listwriter.writerow(ridge.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run bootstrap\n",
    "with open('clean_l_hemisphere_coefficients_wcovariates_010819.csv', 'w') as csvfile:\n",
    "    listwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in range(n_iterations):\n",
    "        # prepare train and test sets\n",
    "        train = resample(vals, n_samples=n_size)\n",
    "        test = np.array([x for x in vals if x.tolist() not in train.tolist()])\n",
    "        # fit model\n",
    "        ridge.fit(train[:,[23, 25, 27, 29, 31, 35, 37, 2, 44, 45]], train[:,17])\n",
    "        # evaluate model\n",
    "        predictions = ridge.predict(test[:,[23, 25, 27, 29, 31, 35, 37, 2, 44, 45]])\n",
    "        listwriter.writerow(ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Incorporate Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = '/Users/leighgayle/Box Sync/Final_619_Docs/NeuroImage_Submission/R&R/clean_updated_datafile_nomissingincome.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(filename2, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_r_ses = data2.Threat_Act_Ramy_NoScalp\n",
    "X_r_ses = data2[[\"RAmySeed_BA25Target\",\"RAmySeed_BA24Target\",\"RAmySeed_BA32Target\",\"RAmySeed_BA10Target\", \"RAmySeed_BA9Target\",\"RAmySeed_BA11Target\",\"RAmySeed_BA47Target\",\"puberty_score\",\"Gender\",\"Internalizing\",\"yr_income\"]]\n",
    "\n",
    "y_l_ses = data2.Threat_Act_Lamy_NoScalp\n",
    "X_l_ses = data2[[\"LAmySeed_BA25Target\",\"LAmySeed_BA24Target\",\"LAmySeed_BA32Target\",\"LAmySeed_BA10Target\", \"LAmySeed_BA9Target\",\"LAmySeed_BA11Target\",\"LAmySeed_BA47Target\",\"puberty_score\",\"Gender\",\"Internalizing\",\"yr_income\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_R_SES, permuatation_scores_R_SES, pvalue_R_SES = permutation_test_score(ridge, X_r_ses, y_r_ses, cv=6, scoring = 'neg_mean_squared_error', n_permutations=5000, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_R_SES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_R_SES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_L_SES, permuatation_scores_L_SES, pvalue_L_SES = permutation_test_score(ridge, X_l_ses, y_l_ses, cv=6, scoring = 'neg_mean_squared_error', n_permutations=5000, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_L_SES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_L_SES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals2 = data2.values\n",
    "n_iterations = 1000\n",
    "n_size = int(len(vals2) * 0.84)\n",
    "\n",
    "# run bootstrap\n",
    "with open('clean_r_hemisphere_coefficients_wcovariatesincSES_011019.csv', 'w') as csvfile:\n",
    "    listwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in range(n_iterations):\n",
    "        # prepare train and test sets\n",
    "        train = resample(vals2, n_samples=n_size)\n",
    "        test = np.array([x for x in vals2 if x.tolist() not in train.tolist()])\n",
    "        # fit model\n",
    "        ridge.fit(train[:,[24, 26, 28, 30, 32, 36, 38, 2, 44, 45, 43]], train[:,16])\n",
    "        # evaluate model\n",
    "        predictions = ridge.predict(test[:,[24, 26, 28, 30, 32, 36, 38, 2, 44, 45, 43]])\n",
    "        listwriter.writerow(ridge.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run bootstrap\n",
    "with open('clean_l_hemisphere_coefficients_wcovariatesincSES_011019.csv', 'w') as csvfile:\n",
    "    listwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in range(n_iterations):\n",
    "        # prepare train and test sets\n",
    "        train = resample(vals2, n_samples=n_size)\n",
    "        test = np.array([x for x in vals2 if x.tolist() not in train.tolist()])\n",
    "        # fit model\n",
    "        ridge.fit(train[:,[23, 25, 27, 29, 31, 35, 37, 2, 44, 45, 43]], train[:,17])\n",
    "        # evaluate model\n",
    "        predictions = ridge.predict(test[:,[23, 25, 27, 29, 31, 35, 37, 2, 44, 45, 43]])\n",
    "        listwriter.writerow(ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test with other emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_R_h, permuatation_scores_R_h, pvalue_R_h = permutation_test_score(ridge, X_r, y_r_happy, cv=6, scoring = 'neg_mean_squared_error', n_permutations=5000, n_jobs=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_R_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = data.values\n",
    "n_iterations = 1000\n",
    "n_size = int(len(vals) * 0.84)\n",
    "\n",
    "# run bootstrap\n",
    "with open('clean_r_hemisphere_coefficients_happy_wcovariates_011019.csv', 'w') as csvfile:\n",
    "    listwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in range(n_iterations):\n",
    "        # prepare train and test sets\n",
    "        train = resample(vals, n_samples=n_size)\n",
    "        test = np.array([x for x in vals if x.tolist() not in train.tolist()])\n",
    "        # fit model\n",
    "        ridge.fit(train[:,[24, 26, 28, 30, 32, 36, 38, 2, 44, 45]], train[:,47])\n",
    "        # evaluate model\n",
    "        predictions = ridge.predict(test[:,[24, 26, 28, 30, 32, 36, 38, 2, 44, 45]])\n",
    "        listwriter.writerow(ridge.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_L_h, permuatation_scores_L_h, pvalue_L_h = permutation_test_score(ridge, X_l, y_l_happy, cv=6, scoring = 'neg_mean_squared_error', n_permutations=5000, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_L_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run bootstrap\n",
    "with open('clean_l_hemisphere_coefficients_happy_wcovariates_011019.csv', 'w') as csvfile:\n",
    "    listwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in range(n_iterations):\n",
    "        # prepare train and test sets\n",
    "        train = resample(vals, n_samples=n_size)\n",
    "        test = np.array([x for x in vals if x.tolist() not in train.tolist()])\n",
    "        # fit model\n",
    "        ridge.fit(train[:,[23, 25, 27, 29, 31, 35, 37, 2, 44, 45]], train[:,46])\n",
    "        # evaluate model\n",
    "        predictions = ridge.predict(test[:,[23, 25, 27, 29, 31, 35, 37, 2, 44, 45]])\n",
    "        listwriter.writerow(ridge.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_R_s, permuatation_scores_R_s, pvalue_R_s = permutation_test_score(ridge, X_r, y_r_sad, cv=6, scoring = 'neg_mean_squared_error', n_permutations=5000, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_R_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('clean_r_hemisphere_coefficients_sad_wcovariatesincSES_011019.csv', 'w') as csvfile:\n",
    "    listwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in range(n_iterations):\n",
    "        # prepare train and test sets\n",
    "        train = resample(vals, n_samples=n_size)\n",
    "        test = np.array([x for x in vals if x.tolist() not in train.tolist()])\n",
    "        # fit model\n",
    "        ridge.fit(train[:,[24, 26, 28, 30, 32, 36, 38, 2, 44, 45]], train[:,49])\n",
    "        # evaluate model\n",
    "        predictions = ridge.predict(test[:,[24, 26, 28, 30, 32, 36, 38, 2, 44, 45]])\n",
    "        listwriter.writerow(ridge.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_L_s, permuatation_scores_L_s, pvalue_L_s = permutation_test_score(ridge, X_l, y_l_sad, cv=6, scoring = 'neg_mean_squared_error', n_permutations=5000, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_L_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MFQ & SCARED rather than Internalizing Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename3 = '/Users/leighgayle/Box Sync/Final_619_Docs/NeuroImage_Submission/R&R/clean_data_wMFQSCARED.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pd.read_csv(filename3, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_r = data3.Threat_Act_Ramy_NoScalp\n",
    "y_r_happy = data3.happyGTbaseline_right\n",
    "y_r_sad = data3.sadGTbaseline_right\n",
    "X_r_sym = data3[[\"RAmySeed_BA25Target\",\"RAmySeed_BA24Target\",\"RAmySeed_BA32Target\",\"RAmySeed_BA10Target\", \"RAmySeed_BA9Target\",\"RAmySeed_BA11Target\",\"RAmySeed_BA47Target\",\"puberty_score\",\"Gender\",\"MFQ_C_Sum\",\"SCARED_C_Sum\"]]\n",
    "\n",
    "y_l = data3.Threat_Act_Lamy_NoScalp\n",
    "y_l_happy = data3.happyGTbaseline_left\n",
    "y_l_sad = data3.sadGTbaseline_left\n",
    "X_l_sym = data3[[\"LAmySeed_BA25Target\",\"LAmySeed_BA24Target\",\"LAmySeed_BA32Target\",\"LAmySeed_BA10Target\", \"LAmySeed_BA9Target\",\"LAmySeed_BA11Target\",\"LAmySeed_BA47Target\",\"puberty_score\",\"Gender\",\"MFQ_C_Sum\",\"SCARED_C_Sum\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_R_sym, permuatation_scores_R_sym, pvalue_R_sym = permutation_test_score(ridge, X_r_sym, y_r, cv=6, scoring = 'neg_mean_squared_error', n_permutations=5000, n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001999600079984003"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalue_R_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.33856497019967197"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_R_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals3 = data3.values\n",
    "n_iterations = 1000\n",
    "n_size = int(len(vals3) * 0.84)\n",
    "\n",
    "# run bootstrap\n",
    "with open('clean_r_hemisphere_coefficients_wcovariates_MFQ_SCARED_011119.csv', 'w') as csvfile:\n",
    "    listwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in range(n_iterations):\n",
    "        # prepare train and test sets\n",
    "        train = resample(vals3, n_samples=n_size)\n",
    "        test = np.array([x for x in vals3 if x.tolist() not in train.tolist()])\n",
    "        # fit model\n",
    "        ridge.fit(train[:,[24, 26, 28, 30, 32, 36, 38, 2, 44, 54, 55]], train[:,16])\n",
    "        # evaluate model\n",
    "        predictions = ridge.predict(test[:,[24, 26, 28, 30, 32, 36, 38, 2, 44, 54, 55]])\n",
    "        listwriter.writerow(ridge.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_L_sym, permuatation_scores_L_sym, pvalue_L_sym = permutation_test_score(ridge, X_l_sym, y_l, cv=6, scoring = 'neg_mean_squared_error', n_permutations=5000, n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013797240551889621"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalue_L_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2922146206873778"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_L_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals3 = data3.values\n",
    "n_iterations = 1000\n",
    "n_size = int(len(vals3) * 0.84)\n",
    "\n",
    "# run bootstrap\n",
    "with open('clean_l_hemisphere_coefficients_wcovariates_MFQ_SCARED_011119.csv', 'w') as csvfile:\n",
    "    listwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in range(n_iterations):\n",
    "        # prepare train and test sets\n",
    "        train = resample(vals3, n_samples=n_size)\n",
    "        test = np.array([x for x in vals3 if x.tolist() not in train.tolist()])\n",
    "        # fit model\n",
    "        ridge.fit(train[:,[23, 25, 27, 29, 31, 35, 37, 2, 44, 54, 55]], train[:,17])\n",
    "        # evaluate model\n",
    "        predictions = ridge.predict(test[:,[23, 25, 27, 29, 31, 35, 37, 2, 44, 54, 55]])\n",
    "        listwriter.writerow(ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-testing models with income & MFQ/SCARED rather than the internalizing factor score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename4 = '/Users/leighgayle/Box Sync/Final_619_Docs/NeuroImage_Submission/R&R/clean_data_wMFQSCARED_nomissingincome.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = pd.read_csv(filename4, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_r = data4.Threat_Act_Ramy_NoScalp\n",
    "X_r_sym_ses = data4[[\"RAmySeed_BA25Target\",\"RAmySeed_BA24Target\",\"RAmySeed_BA32Target\",\"RAmySeed_BA10Target\", \"RAmySeed_BA9Target\",\"RAmySeed_BA11Target\",\"RAmySeed_BA47Target\",\"puberty_score\",\"Gender\",\"MFQ_C_Sum\",\"SCARED_C_Sum\",\"yr_income\"]]\n",
    "\n",
    "y_l = data4.Threat_Act_Lamy_NoScalp\n",
    "X_l_sym_ses = data4[[\"LAmySeed_BA25Target\",\"LAmySeed_BA24Target\",\"LAmySeed_BA32Target\",\"LAmySeed_BA10Target\", \"LAmySeed_BA9Target\",\"LAmySeed_BA11Target\",\"LAmySeed_BA47Target\",\"puberty_score\",\"Gender\",\"MFQ_C_Sum\",\"SCARED_C_Sum\",\"yr_income\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_R_sym_ses, permuatation_scores_R_sym_ses, pvalue_R_sym_ses = permutation_test_score(ridge, X_r_sym_ses, y_r, cv=6, scoring = 'neg_mean_squared_error', n_permutations=5000, n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_R_sym_ses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals4 = data4.values\n",
    "n_iterations = 1000\n",
    "n_size = int(len(vals4) * 0.84)\n",
    "\n",
    "# run bootstrap\n",
    "with open('clean_r_hemisphere_coefficients_wcovariates_MFQ_SCARED_income_011119.csv', 'w') as csvfile:\n",
    "    listwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in range(n_iterations):\n",
    "        # prepare train and test sets\n",
    "        train = resample(vals4, n_samples=n_size)\n",
    "        test = np.array([x for x in vals4 if x.tolist() not in train.tolist()])\n",
    "        # fit model\n",
    "        ridge.fit(train[:,[24, 26, 28, 30, 32, 36, 38, 2, 44, 54, 55, 43]], train[:,16])\n",
    "        # evaluate model\n",
    "        predictions = ridge.predict(test[:,[24, 26, 28, 30, 32, 36, 38, 2, 44, 54, 55, 43]])\n",
    "        listwriter.writerow(ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as previously -- income is not a significant predictor, but we lose BA10 as a significant predictor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_L_sym_ses, permuatation_scores_L_sym_ses, pvalue_L_sym_ses = permutation_test_score(ridge, X_l_sym_ses, y_l, cv=6, scoring = 'neg_mean_squared_error', n_permutations=5000, n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_L_sym_ses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run bootstrap\n",
    "with open('clean_l_hemisphere_coefficients_wcovariates_MFQ_SCARED_income_011119.csv', 'w') as csvfile:\n",
    "    listwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in range(n_iterations):\n",
    "        # prepare train and test sets\n",
    "        train = resample(vals4, n_samples=n_size)\n",
    "        test = np.array([x for x in vals4 if x.tolist() not in train.tolist()])\n",
    "        # fit model\n",
    "        ridge.fit(train[:,[23, 25, 27, 29, 31, 35, 37, 2, 44, 54, 55, 43]], train[:,17])\n",
    "        # evaluate model\n",
    "        predictions = ridge.predict(test[:,[23, 25, 27, 29, 31, 35, 37, 2, 44, 54, 55, 43]])\n",
    "        listwriter.writerow(ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as when controlling for just internalizing factor score -- income is not a significant predictor, but we lose BA11 as a significant predictor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-testing the models with the other emotions controlling for regular covariates (not income). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_R_sym_h, permuatation_scores_R_sym_h, pvalue_R_sym_h = permutation_test_score(ridge, X_r_sym, y_r_happy, cv=6, scoring = 'neg_mean_squared_error', n_permutations=5000, n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01899620075984803"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalue_R_sym_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.22728981245140134"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_R_sym_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run bootstrap\n",
    "with open('clean_r_hemisphere_coefficients_wcovariates_MFQ_SCARED_happy_011119.csv', 'w') as csvfile:\n",
    "    listwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in range(n_iterations):\n",
    "        # prepare train and test sets\n",
    "        train = resample(vals3, n_samples=n_size)\n",
    "        test = np.array([x for x in vals3 if x.tolist() not in train.tolist()])\n",
    "        # fit model\n",
    "        ridge.fit(train[:,[24, 26, 28, 30, 32, 36, 38, 2, 44, 54, 55]], train[:,47])\n",
    "        # evaluate model\n",
    "        predictions = ridge.predict(test[:,[24, 26, 28, 30, 32, 36, 38, 2, 44, 54, 55]])\n",
    "        listwriter.writerow(ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as with the internalizing factor score -- signifciant model with BA10 and BA47 as significant predictors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_L_sym_h, permuatation_scores_L_sym_h, pvalue_L_sym_h = permutation_test_score(ridge, X_l_sym, y_l_happy, cv=6, scoring = 'neg_mean_squared_error', n_permutations=5000, n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01259748050389922"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalue_L_sym_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1513684443468151"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_L_sym_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals3 = data3.values\n",
    "n_iterations = 1000\n",
    "n_size = int(len(vals3) * 0.84)\n",
    "\n",
    "# run bootstrap\n",
    "with open('clean_l_hemisphere_coefficients_wcovariates_MFQ_SCARED_happy_011119.csv', 'w') as csvfile:\n",
    "    listwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in range(n_iterations):\n",
    "        # prepare train and test sets\n",
    "        train = resample(vals3, n_samples=n_size)\n",
    "        test = np.array([x for x in vals3 if x.tolist() not in train.tolist()])\n",
    "        # fit model\n",
    "        ridge.fit(train[:,[23, 25, 27, 29, 31, 35, 37, 2, 44, 54, 55]], train[:,46])\n",
    "        # evaluate model\n",
    "        predictions = ridge.predict(test[:,[23, 25, 27, 29, 31, 35, 37, 2, 44, 54, 55]])\n",
    "        listwriter.writerow(ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significant model with BA10 as the only tract that is a unique predictor of variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_R_sym_s, permuatation_scores_R_sym_s, pvalue_R_sym_s = permutation_test_score(ridge, X_r_sym, y_r_sad, cv=6, scoring = 'neg_mean_squared_error', n_permutations=5000, n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006998600279944011"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalue_R_sym_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.17074893176829298"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_R_sym_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run bootstrap\n",
    "with open('clean_r_hemisphere_coefficients_wcovariates_MFQ_SCARED_sad_011119.csv', 'w') as csvfile:\n",
    "    listwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in range(n_iterations):\n",
    "        # prepare train and test sets\n",
    "        train = resample(vals3, n_samples=n_size)\n",
    "        test = np.array([x for x in vals3 if x.tolist() not in train.tolist()])\n",
    "        # fit model\n",
    "        ridge.fit(train[:,[24, 26, 28, 30, 32, 36, 38, 2, 44, 54, 55]], train[:,49])\n",
    "        # evaluate model\n",
    "        predictions = ridge.predict(test[:,[24, 26, 28, 30, 32, 36, 38, 2, 44, 54, 55]])\n",
    "        listwriter.writerow(ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significant model with BA9 and BA47 as (negative) significant predictors. No positive predictors when controlling for MFQ/SCARED rather than the internalizing factor score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_L_sym_s, permuatation_scores_L_sym_s, pvalue_L_sym_s = permutation_test_score(ridge, X_l_sym, y_l_sad, cv=6, scoring = 'neg_mean_squared_error', n_permutations=5000, n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_L_sym_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a significant model in the left hemisphere for sad activation, so I did not run the bootstrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
